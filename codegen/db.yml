alpaca:
  id: alpaca
  name: Alpaca
  system:
    schema: "{system}"
    message: "Below is an instruction that describes a task. Write a response that appropriately completes the request."
  user: |-
    ### Instruction:
    {prompt}
  assistant: "### Response:"
  linebreaks:
    system: 2
    user: 2
chatml:
  id: "chatml"
  name: "ChatMl"
  system:
    schema: |-
      <|im_start|>system
      {system}<|im_end|>
  user: |-
    <|im_start|>user
    {prompt}<|im_end|>
  assistant: "<|im_start|>assistant"
  linebreaks:
    system: 1
    user: 1
    assistant: 1
  stop:
    - "<|im_end|>"
  afterShot: "<|im_end|>\n"
  tags:
    think:
        start: <think>
        end: </think>
chatml-tools:
  id: "chatml-tools"
  name: "ChatMl tools"
  system:
    schema: "<|im_start|>system\n{system}<|im_end|>"
    message: |-
      You are a helpful assistant with tool calling capabilities. You may call one or more functions to assist with the user query.
      You are provided with function signatures within <tools></tools> XML tags:
      <tools>
      {tools}
      </tools>
      
      For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
      <tool_call>
      [{"name": <function-name>, "arguments": <args-json-object>}]
      </tool_call>
  user: |-
    <|im_start|>user
    {prompt}<|im_end|>
  assistant: "<|im_start|>assistant"
  linebreaks:
    system: 1
    user: 1
    assistant: 1
  stop:
    - "<|im_end|>"
  afterShot: "<|im_end|>\n"
  tools:
    def: "{system}"
    call: |-
      <tool_call>
      {tools}
      </tool_call>
    response: |- 
      <|im_start|>user
      <tool_response>
      {tools_response}
      </tool_response><|im_end|>
      
  tags:
    think:
      start: <think>
      end: </think>
    toolCall:
      start: <tool_call>
      end: </tool_call>
codestral:
  id: codestral
  name: Codestral
  user: "[INST] {prompt}"
  assistant: " [/INST]"
  stop:
    - "</s>"
  afterShot: "\n"
  linebreaks:
    system: 2
  system:
    schema: |-
      <<SYS>>
      {system}
      <</SYS>>
command-r:
  id: command-r
  name: Command-R
  user: "<|START_OF_TURN_TOKEN|><|USER_TOKEN|>{prompt}<|END_OF_TURN_TOKEN|>"
  assistant: "<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>"
  prefix: "<BOS_TOKEN>"
  stop:
    - "<|END_OF_TURN_TOKEN|>"
  linebreaks:
    user: 1
  system:
    schema: "<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>{system}<|END_OF_TURN_TOKEN|>"
deephermes:
  id: deephermes
  name: Deephermes
  user: |-
    <|start_header_id|>user<|end_header_id|>
    {prompt}<|eot_id|>
  assistant: "<|start_header_id|>assistant<|end_header_id|>"
  stop:
    - "<|eot_id|>"
    - "<|end_of_text|>"
  afterShot: "<|eot_id|>\n\n"
  system:
    schema: |-
      <|start_header_id|>system<|end_header_id|>
      
      {system}<|eot_id|>
    message: |-
      You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools: <tools> {tools} </tools>. For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:
      <tool_call>
      [{"arguments": <args-dict>, "name": <function-name>}]
      </tool_call>
  tools:
    def: "{system}"
    call: |-
      <tool_call>
      {tools}
      </tool_call>
    response: |-
      <|start_header_id|>user<|end_header_id|>
      <tool_response>
      {tools_response}
      </tool_response><|eot_id|>

deepseek:
  id: deepseek
  name: Deepseek
  system:
    schema: "{system}"
    message: "You are an AI programming assistant, utilizing the DeepSeek Coder model, developed by DeepSeek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer."
  afterShot: "\n"
  user: |-
    ### Instruction:
    {prompt}
  assistant: "### Response:"
  linebreaks:
    user: 1
    system: 1
  stop:
    - "<|EOT|>"
    - "### Instruction:"
deepseek2:
  id: deepseek2
  name: Deepseek 2
  system:
    schema: "<｜begin▁of▁sentence｜>{system}"
  user: "User: {prompt}"
  assistant: "Assistant:"
  linebreaks:
    user: 2
    system: 2
  stop:
    - "<｜end▁of▁sentence｜>"
    - "<｜tool▁calls▁end｜>"
deepseek3:
  id: deepseek3
  name: Deepseek 3
  system:
    schema: "<｜begin▁of▁sentence｜>{system}"
  user: "<｜User｜>{prompt}"
  assistant: "<｜Assistant｜>"
  linebreaks:
    user: 2
    system: 2
  stop:
    - "<｜end▁of▁sentence｜>"
    - "<｜tool▁calls▁end｜>"
  afterShot: "<｜end▁of▁sentence｜>"
exaone:
  id: exaone
  name: Exaone
  system:
    schema: "[|system|]{system}[|endofturn|]"
    message: You are EXAONE model from LG AI Research, a helpful assistant.
  user: "[|user|]{prompt}[|endofturn|]"
  assistant: "[|assistant|]"
  afterShot: "[|endofturn|]"
  stop:
    - "[|endofturn|]"
  linebreaks:
    user: 1
    system: 1
gemma:
  id: gemma
  name: Gemma
  user: |-
    <start_of_turn>user
    {prompt}
     <end_of_turn>
     
  assistant: |-   
    <start_of_turn>model
  stop:
    - "<end_of_turn>"
  afterShot: "<end_of_turn>"
glm:
  id: glm
  name: Glm
  prefix: "[gMASK]<sop>"
  system: 
    schema: <|system|>{system}
  user: |-
    <|user|>
    {prompt}
  assistant: <|assistant|>
  stop: 
    - "<sop>"
  afterShot: "\n"
glm-tools:
  id: glm-tools
  name: Glm tools
  prefix: "[gMASK]<sop>"
  system: 
    schema: <|system|>{system}
    message: |-
      # Tools

      You may call one or more functions to assist with the user query.

      You are provided with function signatures within <tools></tools> XML tags:
      <tools>
      {tools}
      </tools>

      For each function call, output the function name and arguments within the following XML format:
      <tool_call>{function-name}
      <arg_key>{arg-key-1}</arg_key>
      <arg_value>{arg-value-1}</arg_value>
      <arg_key>{arg-key-2}</arg_key>
      <arg_value>{arg-value-2}</arg_value>
      ...
      </tool_call>
  user: |-
    <|user|>
    {prompt}
  assistant: <|assistant|>
  stop: 
    - "<sop>"
  afterShot: "\n"
  tools:
    def: "{system}"
    call: |-
      <tool_call>
      {tools}
      </tool_call>
    response: |- 
      <tool_response>
      {tools_response}
      </tool_response>
granite:
  id: granite
  name: Granite
  user: "<|start_of_role|>user<|end_of_role|>{prompt}<|end_of_text|>"
  assistant: "<|start_of_role|>assistant<|end_of_role|>"
  stop:
    - "<|end_of_text|>"
    - "<|start_of_role|>"
  system:
    schema: "<|start_of_role|>system<|end_of_role|>{system}<|end_of_text|>"
    message: "You are Granite, developed by IBM. You are a helpful AI assistant."
  linebreaks:
    user: 1
    system: 1
  afterShot: "<|end_of_text|>\n"
granite-think:
  id: granite-think
  name: Granite think
  user: "<|start_of_role|>user<|end_of_role|>{prompt}<|end_of_text|>"
  assistant: "<|start_of_role|>assistant<|end_of_role|>"
  stop:
    - "<|end_of_text|>"
    - "<|start_of_role|>"
  system:
    schema: "<|start_of_role|>system<|end_of_role|>{system}<|end_of_text|>"
    message: "You are Granite, developed by IBM. You are a helpful AI assistant. Respond to every user query in a comprehensive and detailed way. You can write down your thoughts and reasoning process before responding. In the thought process, engage in a comprehensive cycle of analysis, summarization, exploration, reassessment, reflection, backtracing, and iteration to develop well-considered thinking process. In the response section, based on various attempts, explorations, and reflections from the thoughts section, systematically present the final solution that you deem correct. The response should summarize the thought process. Write your thoughts after 'Here is my thought process:' and write your response after 'Here is my response:' for each user query."
  linebreaks:
    user: 1
    system: 1
  afterShot: "<|end_of_text|>\n"
granite-tools:
  id: granite-tools
  name: Granite tools
  user: "<|start_of_role|>user<|end_of_role|>{prompt}<|end_of_text|>"
  assistant: "<|start_of_role|>assistant<|end_of_role|>"
  stop:
    - "<|end_of_text|>"
    - "<|start_of_role|>"
  system:
    schema: "<|start_of_role|>system<|end_of_role|>{system}<|end_of_text|>"
    message: "You are Granite, developed by IBM. You are a helpful AI assistant with access to the following tools. When a tool is required to answer the user's query, respond with <|tool_call|> followed by a JSON list of tools used. If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request."
  tools:
    def: "<|start_of_role|>tools<|end_of_role|>{tools}<|end_of_text|>"
    call: "<|tool_call|>{tools}"
    response: "<|start_of_role|>tool_response<|end_of_role|>{tools_response}<|end_of_text|>\n"
  linebreaks:
    user: 1
    system: 1
    tools: 1
  afterShot: "<|end_of_text|>\n"
  tags:
    toolCall:
        start: <|tool_call|>
        end: <|start_of_role|>
llama:
  id: llama
  name: Llama
  system:
    schema: |-
      [INST] <<SYS>>
      {system}
      <</SYS>>
    message: |-
      You are a helpful, respectful and honest assistant. Always answer as helpfully as possible
      
      If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.
  user: "{prompt}"
  assistant: " [/INST] "
  linebreaks:
    system: 2
    user: 0
  prefix: "<s>"
  stop:
    - "</s>"
llama3:
  id: llama3
  name: Llama 3
  user: |-
    <|start_header_id|>user<|end_header_id|>
    
    {prompt}<|eot_id|>
  assistant: "<|start_header_id|>assistant<|end_header_id|>"
  stop:
    - "<|eot_id|>"
    - "<|end_of_text|>"
  afterShot: "<|eot_id|>\n\n"
  system:
    schema: |-
      <|start_header_id|>system<|end_header_id|>
      
      {system}<|eot_id|>
llama3-think:
  id: llama3-think
  name: Llama 3 think
  user: |-
    <|start_header_id|>user<|end_header_id|>
    
    {prompt}<|eot_id|>
  assistant: "<|start_header_id|>assistant<|end_header_id|>"
  stop:
    - "<|eot_id|>"
    - "<|end_of_text|>"
  afterShot: "<|eot_id|>\n\n"
  system:
    schema: |-
      <|start_header_id|>system<|end_header_id|>
      
      {system}<|eot_id|>
    message: "You are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside <think> </think> tags, and then provide your solution or response to the problem."
  tags:
    think:
      start: <think>
      end: </think>
llava:
  id: llava
  name: Llava
  user: "USER: {prompt}"
  assistant: "ASSISTANT:"
  linebreaks:
    user: 1
minichat:
  id: minichat
  name: Minichat
  user: "[|User|] {prompt} </s>"
  assistant: "[|Assistant|]"
  stop:
    - "</s>"
    - "[|User|]"
  afterShot: "\n"
  prefix: "<s> "
mistral:
  id: mistral
  name: Mistral
  user: "[INST] {prompt}"
  assistant: " [/INST]"
  stop:
    - "</s>"
  afterShot: "\n"
mistral-system:
  id: mistral-system
  name: Mistral system
  user: "[INST] {prompt}"
  assistant: " [/INST]"
  system:
    schema: "[SYSTEM_PROMPT]{system}[/SYSTEM_PROMPT] "
  stop:
    - "</s>"
  afterShot: "\n"
mistral-system-tools:
  id: mistral-system-tools
  name: Mistral system tools
  user: "[INST] {prompt} [/INST]"
  assistant: ""
  system:
    schema: "[SYSTEM_PROMPT]{system}[/SYSTEM_PROMPT] "
  stop:
    - "</s>"
  afterShot: "\n"
  tools:
    def: "[AVAILABLE_TOOLS]{tools}[/AVAILABLE_TOOLS]"
    call: "[TOOL_CALLS]{tools}"
    response: "[TOOL_RESULTS]{tools_response}[/TOOL_RESULTS]"
  tags:
    toolCall:
      start: "[TOOL_CALLS]"
      end: "[/TOOL_RESULTS]"
nemotron:
  id: nemotron
  name: Nemotron
  user: |-
    <extra_id_1>User
    {prompt}
  assistant: "<extra_id_1>Assistant\n"
  linebreaks:
    system: 2
    user: 1
  system:
    schema: |-
      <extra_id_0>System
      {system}
  afterShot: "\n\n"
none:
  id: none
  name: No template
  user: "{prompt}"
  assistant: ""
openchat:
  id: openchat
  name: OpenChat
  user: "GPT4 User: {prompt}<|end_of_turn|>"
  assistant: "GPT4 Assistant:"
  stop:
    - "<|end_of_turn|>"
openchat-correct:
  id: openchat-correct
  name: OpenChat correct
  user: "GPT4 Correct User: {prompt}<|end_of_turn|>"
  assistant: "GPT4 Correct Assistant:"
  stop:
    - "<|end_of_turn|>"
orca:
  id: orca
  name: Orca
  system:
    schema: |-
      ### System:
      {system}
    message: "You are an AI assistant that follows instruction extremely well. Help as much as you can."
  user: |-
    ### User:
    {prompt}
  assistant: "### Response:"
  linebreaks:
    system: 2
    user: 2
phi3:
  id: phi3
  name: Phi 3
  user: "<|user|> {prompt}<|end|>"
  assistant: "<|assistant|>"
  system:
    schema: "<|system|> {system}<|end|>"
  afterShot: "<|end|>\n"
  stop:
    - "<|end|>"
    - "<|user|>"
phi4:
  id: phi4
  name: Phi 4
  system:
    schema: "<|im_start|>system<|im_sep|>{system}<|im_end|>"
  user: "<|im_start|>user<|im_sep|>{prompt}<|im_end|>"
  assistant: "<|im_start|>assistant<|im_sep|>"
  stop:
    - "<|im_end|>"
    - "<|im_sep|>"
  afterShot: "<|im_end|>\n"
phi4-tools:
  id: phi4-tools
  name: Phi 4 tools
  system:
    schema: "<|im_start|>system<|im_sep|>{system}<|im_end|>"
    message: |-
      You are a helpful assistant with some tools.
      <|tool|>
      {tools}
      <|/tool|>
  user: "<|im_start|>user<|im_sep|>{prompt}<|im_end|>"
  assistant: "<|im_start|>assistant<|im_sep|>"
  stop:
    - "<|im_end|>"
    - "<|im_sep|>"
  afterShot: "<|im_end|>\n"
  tools:
    def: "{system}"
    call: |-
      <|tool_call|>
      {tools}
      <|/tool_call|>
    response: |- 
      <|im_start|>user
      <|tool_response|>
      {tools_response}
      <|/tool_response|><|im_end|>
  tags:
    toolCall:
      start: <|tool_call|>
      end: <|/tool_call|>
reka:
  id: reka
  name: Reka
  user: "human: {prompt} <sep> "
  assistant: "assistant:"
  stop:
    - "<sep>"
    - "<|endoftext|>"
  afterShot: " <sep> "
vicuna:
  id: vicuna
  name: Vicuna
  user: "USER: {prompt}"
  assistant: "### ASSISTANT:"
  linebreaks:
    user: 2
vicuna_system:
  id: vicuna_system
  name: Vicuna system
  system:
    schema: "SYSTEM: {system}"
  user: "USER: {prompt}"
  assistant: "### ASSISTANT:"
  linebreaks:
    system: 2
    user: 2
wizard_vicuna:
  id: wizard_vicuna
  name: Wizard Vicuna
  user: |-
    ### Human:
    {prompt}
  assistant: "### ASSISTANT:"
  linebreaks:
    user: 2
  stop:
    - "<|endoftext|>"
wizardlm:
  id: wizardlm
  name: WizardLM
  system:
    schema: "{system}"
    message: "You are a helpful AI assistant."
  user: "USER: {prompt}"
  assistant: "ASSISTANT:"
  linebreaks:
    user: 1
zephyr:
  id: zephyr
  name: Zephyr
  system:
    schema: |-
      <|system|>
      {system}<|endoftext|>
  user: |-
    <|user|>
    {prompt}<|endoftext|>
  assistant: "<|assistant|>"
  linebreaks:
    system: 1
    user: 1
    assistant: 1
  afterShot: "\n"
  stop:
    - "<|endoftext|>"
